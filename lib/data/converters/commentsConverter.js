/**
 * COMMENTS CONVERTER
 * Converts TheYouTubeTool comments export
 */

import fs from 'fs/promises';
import path from 'path';
import { parseCSV } from './csvParser.js';
import { filterUsefulComments } from '../../commentFilter.js';

export async function convertComments(inputPaths, outputPath) {
  console.log('ðŸ’¬ Converting comments...');
  
  let allComments = [];
  
  for (const inputPath of inputPaths) {
    try {
      const content = await fs.readFile(inputPath, 'utf-8');
      const rows = parseCSV(content);
      allComments.push(...rows);
      console.log(`   âœ… Loaded ${rows.length} comments from ${path.basename(inputPath)}`);
    } catch (e) {
      console.log(`   âš ï¸ Skipped ${inputPath}: ${e.message}`);
    }
  }
  
  // Convert all comments first
  const allConvertedComments = allComments.map((row, index) => {
    const text = cleanComment(row['Comment'] || row['comment'] || row['Text'] || row['text'] || '');
    const analysis = analyzeComment(text);
    
    return {
      id: `comment_${index}`,
      author: (row['Author'] || row['author'] || '').replace('@', ''),
      text,
      likes: parseInt(row['Likes'] || row['likes'] || row['Like Count'] || row['like_count'] || 0) || 0,
      replies: parseInt(row['Replies'] || row['replies'] || row['Reply Count'] || row['reply_count'] || 0) || 0,
      date: row['Date'] || row['date'] || row['Published'] || row['published'] || '',
      videoId: row['Video ID'] || row['Video id'] || row['video_id'] || '',
      videoTitle: row['Video Title'] || row['Video title'] || row['video_title'] || '',
      
      type: analysis.type,
      sentiment: analysis.sentiment,
      topic: analysis.topic,
      question: analysis.question,
      request: analysis.request,
      isActionable: analysis.isActionable
    };
  });
  
  // Filter out appreciation/spam comments
  const comments = filterUsefulComments(allConvertedComments);
  console.log(`   ðŸ“Š Filtered ${allConvertedComments.length} â†’ ${comments.length} useful comments`);
  
  comments.sort((a, b) => b.likes - a.likes);
  
  const questions = comments.filter(c => c.type === 'question');
  const requests = comments.filter(c => c.type === 'request');
  
  const insights = {
    topQuestions: questions.slice(0, 20).map(q => ({
      question: q.question,
      author: q.author,
      likes: q.likes,
      topic: q.topic
    })),
    topRequests: requests.slice(0, 20).map(r => ({
      request: r.request,
      author: r.author,
      likes: r.likes,
      topic: r.topic
    })),
    videoIdeas: [...questions, ...requests]
      .filter(c => c.isActionable)
      .slice(0, 15)
      .map(c => ({
        idea: c.question || c.request,
        type: c.type,
        likes: c.likes,
        topic: c.topic
      })),
    stats: {
      total: comments.length,
      questions: questions.length,
      requests: requests.length,
      positive: comments.filter(c => c.sentiment === 'positive').length
    }
  };
  
  const output = { comments, insights, meta: { total: comments.length, convertedAt: new Date().toISOString() } };
  
  await fs.mkdir(path.dirname(outputPath), { recursive: true });
  await fs.writeFile(outputPath, JSON.stringify(output, null, 2));
  
  console.log(`   âœ… Converted ${comments.length} total comments`);
  return output;
}

function cleanComment(text) {
  if (!text) return '';
  return text
    .replace(/<[^>]*>/g, ' ')
    .replace(/&amp;/g, '&')
    .replace(/&lt;/g, '<')
    .replace(/&gt;/g, '>')
    .replace(/&#39;/g, "'")
    .replace(/&quot;/g, '"')
    .replace(/\s+/g, ' ')
    .trim();
}

function analyzeComment(text) {
  if (!text) return { type: 'other', sentiment: 'neutral', isActionable: false };
  
  const lower = text.toLowerCase();
  let type = 'other';
  let question = null;
  let request = null;
  
  // Question detection
  if (text.includes('ØŸ') || text.includes('?') ||
      lower.includes('Ù‡Ù„ ') || lower.includes('ÙƒÙŠÙ ') ||
      lower.includes('Ù„Ù…Ø§Ø°Ø§ ') || lower.includes('Ù„ÙŠÙ‡ ') ||
      lower.includes('Ø§Ø²Ø§ÙŠ ') || lower.includes('Ù…Ø§ Ù‡Ùˆ') ||
      lower.includes('Ù…ØªÙ‰ ') || lower.includes('Ø£ÙŠÙ† ') ||
      lower.includes('Ù…Ù† ')) {
    type = 'question';
    question = extractQuestion(text);
  }
  // Request detection
  else if (lower.includes('Ù…Ù…ÙƒÙ†') || lower.includes('ÙŠØ§Ø±ÙŠØª') ||
           lower.includes('ÙŠØ§ Ø±ÙŠØª') || lower.includes('Ù†Ø±ÙŠØ¯') ||
           lower.includes('Ø§ØªÙ…Ù†Ù‰') || lower.includes('Ø­Ù„Ù‚Ø© Ø¹Ù†') ||
           lower.includes('ØªØªÙƒÙ„Ù… Ø¹Ù†') || lower.includes('ØªØªØ­Ø¯Ø« Ø¹Ù†') ||
           lower.includes('ÙÙŠØ¯ÙŠÙˆ Ø¹Ù†') || lower.includes('Ù…ÙˆØ¶ÙˆØ¹ Ø¹Ù†')) {
    type = 'request';
    request = extractRequest(text);
  }
  // Praise
  else if (lower.includes('Ù…Ù…ØªØ§Ø²') || lower.includes('Ø±Ø§Ø¦Ø¹') ||
           lower.includes('Ù…Ø¨Ø¯Ø¹') || lower.includes('Ø´ÙƒØ±') ||
           text.includes('â¤') || text.includes('ðŸ‘') ||
           lower.includes('Ø§Ø­Ø³Ù†') || lower.includes('Ø£ÙØ¶Ù„')) {
    type = 'praise';
  }
  
  // Sentiment
  let sentiment = 'neutral';
  if (text.includes('â¤') || lower.includes('Ø´ÙƒØ±') || lower.includes('Ø±Ø§Ø¦Ø¹') ||
      lower.includes('Ù…Ù…ØªØ§Ø²') || lower.includes('Ù…Ø¨Ø¯Ø¹')) {
    sentiment = 'positive';
  } else if (lower.includes('Ø³ÙŠØ¡') || lower.includes('Ù…Ø´ Ø¹Ø§Ø¬Ø¨') ||
             lower.includes('Ù…Ø´ Ø­Ù„Ùˆ') || lower.includes('Ù…Ø´ Ø¹Ø¬Ø¨')) {
    sentiment = 'negative';
  }
  
  // Topic
  const topic = detectTopic(lower);
  
  return {
    type,
    sentiment,
    topic,
    question,
    request,
    isActionable: type === 'question' || type === 'request'
  };
}

function extractQuestion(text) {
  const sentences = text.split(/[.!ØŒ]/);
  for (const s of sentences) {
    if (s.includes('ØŸ') || s.includes('?')) {
      return s.trim().substring(0, 200);
    }
  }
  return text.substring(0, 200);
}

function extractRequest(text) {
  const patterns = [
    /Ù…Ù…ÙƒÙ† (.+)/,
    /ÙŠØ§ ?Ø±ÙŠØª (.+)/,
    /Ù†Ø±ÙŠØ¯ (.+)/,
    /Ø§ØªÙ…Ù†Ù‰ (.+)/,
    /Ø­Ù„Ù‚Ø© Ø¹Ù† (.+)/,
    /ØªØªÙƒÙ„Ù… Ø¹Ù† (.+)/,
    /ÙÙŠØ¯ÙŠÙˆ Ø¹Ù† (.+)/,
    /Ù…ÙˆØ¶ÙˆØ¹ Ø¹Ù† (.+)/
  ];
  for (const pattern of patterns) {
    const match = text.match(pattern);
    if (match) return match[1].substring(0, 150);
  }
  return text.substring(0, 150);
}

function detectTopic(text) {
  const topics = {
    'islamic_economy': ['Ø§Ø³Ù„Ø§Ù…ÙŠ', 'Ø§Ù„Ø±Ø¨Ø§', 'Ø²ÙƒØ§Ø©', 'Ø­Ù„Ø§Ù„', 'Ø­Ø±Ø§Ù…'],
    'egypt': ['Ù…ØµØ±', 'Ù…ØµØ±ÙŠ', 'Ø§Ù„Ø¬Ù†ÙŠÙ‡', 'Ø§Ù„Ø³ÙŠØ³ÙŠ'],
    'gold': ['Ø°Ù‡Ø¨', 'gold'],
    'real_estate': ['Ø¹Ù‚Ø§Ø±', 'Ø¹Ù‚Ø§Ø±Ø§Øª', 'Ø´Ù‚Ø©', 'Ø£Ø±Ø¶'],
    'investment': ['Ø§Ø³ØªØ«Ù…Ø§Ø±', 'Ø§Ø¯Ø®Ø§Ø±', 'ØªÙˆÙÙŠØ±'],
    'syria': ['Ø³ÙˆØ±ÙŠØ§', 'Ø³ÙˆØ±ÙŠ'],
    'china': ['Ø§Ù„ØµÙŠÙ†', 'ØµÙŠÙ†'],
    'germany': ['Ø§Ù„Ù…Ø§Ù†ÙŠØ§', 'Ø£Ù„Ù…Ø§Ù†ÙŠØ§', 'germany'],
    'saudi': ['Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©', 'Ø³Ø¹ÙˆØ¯ÙŠ'],
    'dollar': ['Ø¯ÙˆÙ„Ø§Ø±', 'Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±'],
    'economy': ['Ø§Ù‚ØªØµØ§Ø¯', 'economic']
  };
  
  for (const [topic, keywords] of Object.entries(topics)) {
    if (keywords.some(k => text.includes(k))) return topic;
  }
  return 'general';
}




